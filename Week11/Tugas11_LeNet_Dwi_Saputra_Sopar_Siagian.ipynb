{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMsmBkc+bv+SHH1IhEM8DaN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoparAwayyy/Machine-Learning/blob/main/Week11/Tugas11_LeNet_Dwi_Saputra_Sopar_Siagian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DWI SAPUTRA SOPAR SIAGIAN\n",
        "\n",
        "1103210220\n",
        "\n",
        "Lecture 11 : Image Classification CIFAR10\n",
        "\n",
        "Dataset : CIFAR10\n",
        "\n",
        "Model : LeNet\n",
        "\n",
        "Dokumentasi ChatGPT : https://chatgpt.com/share/e54ca685-4f86-4ee9-8320-a96438bd6079"
      ],
      "metadata": {
        "id": "29J78MVO8n7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LeNet**\n",
        "\n",
        "LeNet adalah salah satu model Convolutional Neural Network (CNN) yang pertama\n",
        "kali berhasil diterapkan. Model ini diciptakan oleh Yann LeCun bersama timnya\n",
        "pada akhir tahun 1980-an hingga awal 1990-an. Awalnya, LeNet didesain untuk mengenali tulisan tangan dalam proses OCR (Optical Character Recognition) atau pengenalan karakter optik.\n",
        "\n",
        "\n",
        "Meskipun sudah lama diciptakan, LeNet menjadi dasar atau fondasi bagi banyak arsitektur CNN modern saat ini. Bahkan sampai sekarang, LeNet masih sering digunakan sebagai model pembanding (baseline) dalam berbagai tugas atau aplikasi lainnya.\n",
        "\n",
        "\n",
        "Jadi, LeNet merupakan model CNN yang sederhana namun penting karena menjadi cikal bakal berkembangnya CNN modern yang lebih canggih dan kompleks pada masa kini.\n",
        "\n",
        "\n",
        "\n",
        "Arsitektur LeNet-5 yang asli terdiri dari beberapa lapisan sebagai berikut:\n",
        "\n",
        "Input Layer: Gambar input ukuran 32x32.\n",
        "\n",
        "\n",
        "1. Input Layer: Gambar input ukuran 32x32\n",
        "2. Convolutional Layer C1: 6 filter ukuran 5x5, stride 1, dan aktivasi tanh\n",
        "3. Subsampling Layer S2: Pooling layer (average pooling) dengan ukuran 2x2 dan stride 2  \n",
        "4. Convolutional Layer C3: 16 filter ukuran 5x5, stride 1, dan aktivasi tanh.\n",
        "5. Subsampling Layer S4: Pooling layer (average pooling) dengan ukuran 2x2 dan stride 2.\n",
        "6. Fully Connected Layer C5: 120 neurons, fully connected.\n",
        "7. Fully Connected Layer F6: 84 neurons, fully connected.\n",
        "8. Output Layer: 10 neurons dengan softmax untuk klasifikasi.\n"
      ],
      "metadata": {
        "id": "ZAFwimbk90ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Library**"
      ],
      "metadata": {
        "id": "SCjmEoXQ-QvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "5iFSKr_O8nY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load dan Preprocess Dataset CIFAR10**"
      ],
      "metadata": {
        "id": "3CXEQJagCTO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the images to a range of 0 to 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "Hml9yahWCN_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explorasi Dataset**"
      ],
      "metadata": {
        "id": "AQlrT6HCCeqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class names\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Function to plot images\n",
        "def plot_sample_images(x, y, class_names):\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i in np.arange(0, 9):\n",
        "        axes[i].imshow(x[i])\n",
        "        axes[i].set_title(class_names[np.argmax(y[i])])\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.subplots_adjust(wspace=1, hspace=1)\n",
        "    plt.show()\n",
        "\n",
        "# Plot sample images\n",
        "plot_sample_images(x_train, y_train, class_names)"
      ],
      "metadata": {
        "id": "wySAbjIuB_-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membangun Model LeNet**"
      ],
      "metadata": {
        "id": "GPbUnz2yCkei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(6, (5, 5), activation='tanh', input_shape=(32, 32, 3), padding='same'),\n",
        "    AveragePooling2D(),\n",
        "    Conv2D(16, (5, 5), activation='tanh', padding='valid'),\n",
        "    AveragePooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(120, activation='tanh'),\n",
        "    Dense(84, activation='tanh'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "XFnz1E7BYOOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Melihat Arsitektur Model**"
      ],
      "metadata": {
        "id": "uPEIrgc7CnaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "LgFYQbxEYQPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Melatih Model**"
      ],
      "metadata": {
        "id": "hfCPuwH2CqX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    batch_size=64)\n"
      ],
      "metadata": {
        "id": "1DbFrwpZYRpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluasi Model**\n"
      ],
      "metadata": {
        "id": "_3PjkxczCu2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "id": "lou4Oi0nYStm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Hasil Pelatihan**"
      ],
      "metadata": {
        "id": "ifTN9K9kCw1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g2uQ6GsoYTfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membuat Prediksi dan Menampilkan Confusion Matrix**"
      ],
      "metadata": {
        "id": "eXmwItKQC7Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Convert predictions to labels\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(report)\n",
        "\n",
        "# Function to plot sample predictions\n",
        "def plot_sample_predictions(x, y_true, y_pred, class_names):\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i in np.arange(0, 9):\n",
        "        axes[i].imshow(x[i])\n",
        "        true_label = class_names[y_true[i]]\n",
        "        pred_label = class_names[y_pred[i]]\n",
        "        axes[i].set_title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.subplots_adjust(wspace=1, hspace=1)\n",
        "    plt.show()\n",
        "\n",
        "# Plot sample predictions\n",
        "plot_sample_predictions(x_test, y_true, y_pred, class_names)\n"
      ],
      "metadata": {
        "id": "5qGNcId9YUhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan**\n",
        "\n",
        "LeNet merupakan arsitektur CNN legendaris yang menjadi fondasi penting dalam memahami konsep CNN. Implementasi di atas memanfaatkan dataset CIFAR-10 dan menguraikan tahapan mulai dari pemuatan data hingga evaluasi model dengan menggunakan confusion matrix. Anda dapat menyalin kode tersebut ke dalam Google Colab dan menjalankannya untuk menyaksikan secara langsung bagaimana LeNet beroperasi pada dataset CIFAR-10."
      ],
      "metadata": {
        "id": "4Y28gM82DCTU"
      }
    }
  ]
}